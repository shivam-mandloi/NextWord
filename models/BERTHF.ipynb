{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e538057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73505f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:   Hello,,,   WORLD!! 42@@@openAI##   is---great??? \n",
      "\n",
      "   NLP---rocks :)    [unused10] \n",
      "Tokenized input IDs: tensor([[  101,  7592,  1010,  1010,  1010,  2088,   999,   999,  4413,  1030,\n",
      "          1030,  1030,  2330,  4886,  1001,  1001,  2003,  1011,  1011,  1011,\n",
      "          2307,  1029,  1029,  1029, 17953,  2361,  1011,  1011,  1011,  5749,\n",
      "          1024,  1007,  1031, 15171, 10790,  1033,   102]])\n",
      "Last hidden state shape: torch.Size([1, 37, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "\n",
    "def load_bert_base():\n",
    "    \"\"\"\n",
    "    Load Hugging Face's original BERT-base (uncased) model.\n",
    "    - 12 layers\n",
    "    - 12 attention heads\n",
    "    - Hidden size 768\n",
    "    \"\"\"\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer, model = load_bert_base()\n",
    "\n",
    "    # Example input\n",
    "    text = \"  Hello,,,   WORLD!! 42@@@openAI##   is---great??? \\n\\n   NLP---rocks :)    [unused10] \"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Forward pass (get hidden states)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # The last hidden state representation\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "    print(\"Input text:\", text)\n",
    "    print(\"Tokenized input IDs:\", inputs[\"input_ids\"])\n",
    "    print(\"Last hidden state shape:\", last_hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a704b2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07e523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are people of peace. (score: 0.1621)\n",
      "we are people of god. (score: 0.0769)\n",
      "we are people of faith. (score: 0.0533)\n",
      "we are people of honor. (score: 0.0413)\n",
      "we are people of light. (score: 0.0259)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load BERT fill-mask pipeline\n",
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "# Sentence with a [MASK] token\n",
    "text = \"We are people of [MASK].\"\n",
    "\n",
    "# Get predictions\n",
    "predictions = unmasker(text)\n",
    "\n",
    "for pred in predictions:\n",
    "    print(f\"{pred['sequence']} (score: {pred['score']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b57db481",
   "metadata": {},
   "outputs": [],
   "source": [
    "weigthPat = r\"C:\\Users\\shiva\\Desktop\\IISC\\code\\NeuroCpp\\Projects\\The Dream\\weigths\\BERT weights\"\n",
    "def SaveTensor(mat, fileName):\n",
    "    np.save(\n",
    "            os.path.join(weigthPat, fileName),\n",
    "            mat.detach().cpu().numpy().astype(np.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cb89f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveModel(model): # save weights for model\n",
    "    for name, weight in model.named_parameters():\n",
    "        SaveTensor(weight, name)\n",
    "        print(f\"{name} saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5db4da9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight saved\n",
      "embeddings.position_embeddings.weight saved\n",
      "embeddings.token_type_embeddings.weight saved\n",
      "embeddings.LayerNorm.weight saved\n",
      "embeddings.LayerNorm.bias saved\n",
      "encoder.layer.0.attention.self.query.weight saved\n",
      "encoder.layer.0.attention.self.query.bias saved\n",
      "encoder.layer.0.attention.self.key.weight saved\n",
      "encoder.layer.0.attention.self.key.bias saved\n",
      "encoder.layer.0.attention.self.value.weight saved\n",
      "encoder.layer.0.attention.self.value.bias saved\n",
      "encoder.layer.0.attention.output.dense.weight saved\n",
      "encoder.layer.0.attention.output.dense.bias saved\n",
      "encoder.layer.0.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.0.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.0.intermediate.dense.weight saved\n",
      "encoder.layer.0.intermediate.dense.bias saved\n",
      "encoder.layer.0.output.dense.weight saved\n",
      "encoder.layer.0.output.dense.bias saved\n",
      "encoder.layer.0.output.LayerNorm.weight saved\n",
      "encoder.layer.0.output.LayerNorm.bias saved\n",
      "encoder.layer.1.attention.self.query.weight saved\n",
      "encoder.layer.1.attention.self.query.bias saved\n",
      "encoder.layer.1.attention.self.key.weight saved\n",
      "encoder.layer.1.attention.self.key.bias saved\n",
      "encoder.layer.1.attention.self.value.weight saved\n",
      "encoder.layer.1.attention.self.value.bias saved\n",
      "encoder.layer.1.attention.output.dense.weight saved\n",
      "encoder.layer.1.attention.output.dense.bias saved\n",
      "encoder.layer.1.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.1.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.1.intermediate.dense.weight saved\n",
      "encoder.layer.1.intermediate.dense.bias saved\n",
      "encoder.layer.1.output.dense.weight saved\n",
      "encoder.layer.1.output.dense.bias saved\n",
      "encoder.layer.1.output.LayerNorm.weight saved\n",
      "encoder.layer.1.output.LayerNorm.bias saved\n",
      "encoder.layer.2.attention.self.query.weight saved\n",
      "encoder.layer.2.attention.self.query.bias saved\n",
      "encoder.layer.2.attention.self.key.weight saved\n",
      "encoder.layer.2.attention.self.key.bias saved\n",
      "encoder.layer.2.attention.self.value.weight saved\n",
      "encoder.layer.2.attention.self.value.bias saved\n",
      "encoder.layer.2.attention.output.dense.weight saved\n",
      "encoder.layer.2.attention.output.dense.bias saved\n",
      "encoder.layer.2.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.2.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.2.intermediate.dense.weight saved\n",
      "encoder.layer.2.intermediate.dense.bias saved\n",
      "encoder.layer.2.output.dense.weight saved\n",
      "encoder.layer.2.output.dense.bias saved\n",
      "encoder.layer.2.output.LayerNorm.weight saved\n",
      "encoder.layer.2.output.LayerNorm.bias saved\n",
      "encoder.layer.3.attention.self.query.weight saved\n",
      "encoder.layer.3.attention.self.query.bias saved\n",
      "encoder.layer.3.attention.self.key.weight saved\n",
      "encoder.layer.3.attention.self.key.bias saved\n",
      "encoder.layer.3.attention.self.value.weight saved\n",
      "encoder.layer.3.attention.self.value.bias saved\n",
      "encoder.layer.3.attention.output.dense.weight saved\n",
      "encoder.layer.3.attention.output.dense.bias saved\n",
      "encoder.layer.3.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.3.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.3.intermediate.dense.weight saved\n",
      "encoder.layer.3.intermediate.dense.bias saved\n",
      "encoder.layer.3.output.dense.weight saved\n",
      "encoder.layer.3.output.dense.bias saved\n",
      "encoder.layer.3.output.LayerNorm.weight saved\n",
      "encoder.layer.3.output.LayerNorm.bias saved\n",
      "encoder.layer.4.attention.self.query.weight saved\n",
      "encoder.layer.4.attention.self.query.bias saved\n",
      "encoder.layer.4.attention.self.key.weight saved\n",
      "encoder.layer.4.attention.self.key.bias saved\n",
      "encoder.layer.4.attention.self.value.weight saved\n",
      "encoder.layer.4.attention.self.value.bias saved\n",
      "encoder.layer.4.attention.output.dense.weight saved\n",
      "encoder.layer.4.attention.output.dense.bias saved\n",
      "encoder.layer.4.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.4.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.4.intermediate.dense.weight saved\n",
      "encoder.layer.4.intermediate.dense.bias saved\n",
      "encoder.layer.4.output.dense.weight saved\n",
      "encoder.layer.4.output.dense.bias saved\n",
      "encoder.layer.4.output.LayerNorm.weight saved\n",
      "encoder.layer.4.output.LayerNorm.bias saved\n",
      "encoder.layer.5.attention.self.query.weight saved\n",
      "encoder.layer.5.attention.self.query.bias saved\n",
      "encoder.layer.5.attention.self.key.weight saved\n",
      "encoder.layer.5.attention.self.key.bias saved\n",
      "encoder.layer.5.attention.self.value.weight saved\n",
      "encoder.layer.5.attention.self.value.bias saved\n",
      "encoder.layer.5.attention.output.dense.weight saved\n",
      "encoder.layer.5.attention.output.dense.bias saved\n",
      "encoder.layer.5.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.5.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.5.intermediate.dense.weight saved\n",
      "encoder.layer.5.intermediate.dense.bias saved\n",
      "encoder.layer.5.output.dense.weight saved\n",
      "encoder.layer.5.output.dense.bias saved\n",
      "encoder.layer.5.output.LayerNorm.weight saved\n",
      "encoder.layer.5.output.LayerNorm.bias saved\n",
      "encoder.layer.6.attention.self.query.weight saved\n",
      "encoder.layer.6.attention.self.query.bias saved\n",
      "encoder.layer.6.attention.self.key.weight saved\n",
      "encoder.layer.6.attention.self.key.bias saved\n",
      "encoder.layer.6.attention.self.value.weight saved\n",
      "encoder.layer.6.attention.self.value.bias saved\n",
      "encoder.layer.6.attention.output.dense.weight saved\n",
      "encoder.layer.6.attention.output.dense.bias saved\n",
      "encoder.layer.6.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.6.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.6.intermediate.dense.weight saved\n",
      "encoder.layer.6.intermediate.dense.bias saved\n",
      "encoder.layer.6.output.dense.weight saved\n",
      "encoder.layer.6.output.dense.bias saved\n",
      "encoder.layer.6.output.LayerNorm.weight saved\n",
      "encoder.layer.6.output.LayerNorm.bias saved\n",
      "encoder.layer.7.attention.self.query.weight saved\n",
      "encoder.layer.7.attention.self.query.bias saved\n",
      "encoder.layer.7.attention.self.key.weight saved\n",
      "encoder.layer.7.attention.self.key.bias saved\n",
      "encoder.layer.7.attention.self.value.weight saved\n",
      "encoder.layer.7.attention.self.value.bias saved\n",
      "encoder.layer.7.attention.output.dense.weight saved\n",
      "encoder.layer.7.attention.output.dense.bias saved\n",
      "encoder.layer.7.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.7.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.7.intermediate.dense.weight saved\n",
      "encoder.layer.7.intermediate.dense.bias saved\n",
      "encoder.layer.7.output.dense.weight saved\n",
      "encoder.layer.7.output.dense.bias saved\n",
      "encoder.layer.7.output.LayerNorm.weight saved\n",
      "encoder.layer.7.output.LayerNorm.bias saved\n",
      "encoder.layer.8.attention.self.query.weight saved\n",
      "encoder.layer.8.attention.self.query.bias saved\n",
      "encoder.layer.8.attention.self.key.weight saved\n",
      "encoder.layer.8.attention.self.key.bias saved\n",
      "encoder.layer.8.attention.self.value.weight saved\n",
      "encoder.layer.8.attention.self.value.bias saved\n",
      "encoder.layer.8.attention.output.dense.weight saved\n",
      "encoder.layer.8.attention.output.dense.bias saved\n",
      "encoder.layer.8.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.8.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.8.intermediate.dense.weight saved\n",
      "encoder.layer.8.intermediate.dense.bias saved\n",
      "encoder.layer.8.output.dense.weight saved\n",
      "encoder.layer.8.output.dense.bias saved\n",
      "encoder.layer.8.output.LayerNorm.weight saved\n",
      "encoder.layer.8.output.LayerNorm.bias saved\n",
      "encoder.layer.9.attention.self.query.weight saved\n",
      "encoder.layer.9.attention.self.query.bias saved\n",
      "encoder.layer.9.attention.self.key.weight saved\n",
      "encoder.layer.9.attention.self.key.bias saved\n",
      "encoder.layer.9.attention.self.value.weight saved\n",
      "encoder.layer.9.attention.self.value.bias saved\n",
      "encoder.layer.9.attention.output.dense.weight saved\n",
      "encoder.layer.9.attention.output.dense.bias saved\n",
      "encoder.layer.9.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.9.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.9.intermediate.dense.weight saved\n",
      "encoder.layer.9.intermediate.dense.bias saved\n",
      "encoder.layer.9.output.dense.weight saved\n",
      "encoder.layer.9.output.dense.bias saved\n",
      "encoder.layer.9.output.LayerNorm.weight saved\n",
      "encoder.layer.9.output.LayerNorm.bias saved\n",
      "encoder.layer.10.attention.self.query.weight saved\n",
      "encoder.layer.10.attention.self.query.bias saved\n",
      "encoder.layer.10.attention.self.key.weight saved\n",
      "encoder.layer.10.attention.self.key.bias saved\n",
      "encoder.layer.10.attention.self.value.weight saved\n",
      "encoder.layer.10.attention.self.value.bias saved\n",
      "encoder.layer.10.attention.output.dense.weight saved\n",
      "encoder.layer.10.attention.output.dense.bias saved\n",
      "encoder.layer.10.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.10.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.10.intermediate.dense.weight saved\n",
      "encoder.layer.10.intermediate.dense.bias saved\n",
      "encoder.layer.10.output.dense.weight saved\n",
      "encoder.layer.10.output.dense.bias saved\n",
      "encoder.layer.10.output.LayerNorm.weight saved\n",
      "encoder.layer.10.output.LayerNorm.bias saved\n",
      "encoder.layer.11.attention.self.query.weight saved\n",
      "encoder.layer.11.attention.self.query.bias saved\n",
      "encoder.layer.11.attention.self.key.weight saved\n",
      "encoder.layer.11.attention.self.key.bias saved\n",
      "encoder.layer.11.attention.self.value.weight saved\n",
      "encoder.layer.11.attention.self.value.bias saved\n",
      "encoder.layer.11.attention.output.dense.weight saved\n",
      "encoder.layer.11.attention.output.dense.bias saved\n",
      "encoder.layer.11.attention.output.LayerNorm.weight saved\n",
      "encoder.layer.11.attention.output.LayerNorm.bias saved\n",
      "encoder.layer.11.intermediate.dense.weight saved\n",
      "encoder.layer.11.intermediate.dense.bias saved\n",
      "encoder.layer.11.output.dense.weight saved\n",
      "encoder.layer.11.output.dense.bias saved\n",
      "encoder.layer.11.output.LayerNorm.weight saved\n",
      "encoder.layer.11.output.LayerNorm.bias saved\n",
      "pooler.dense.weight saved\n",
      "pooler.dense.bias saved\n"
     ]
    }
   ],
   "source": [
    "SaveModel(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
