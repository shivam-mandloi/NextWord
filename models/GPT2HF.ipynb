{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13e78b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43f67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "embdingPath = r\"C:\\Users\\shiva\\Desktop\\IISC\\code\\NeuroCpp\\Projects\\The Dream\\embedding\"\n",
    "weigthPat = r\"C:\\Users\\shiva\\Desktop\\IISC\\code\\NeuroCpp\\Projects\\The Dream\\weigths\"\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d9a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveTensor(mat, fileName):\n",
    "    np.save(\n",
    "            os.path.join(weigthPat, fileName),\n",
    "            mat.detach().cpu().numpy().astype(np.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "754ce9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you fucking die!!!\" she cries. \"She's going to be an angel. She's gonna die with me!! I'll put that stuff out on the field! I'm gonna go on an island and get to Heaven!!\"\n",
      "\n",
      "While she\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load pre-trained GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set the model in evaluation mode (important when generating text)\n",
    "# model.eval()\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Example input prompt\n",
    "prompt = \"you fucking\"\n",
    "# Tokenize input text and convert to tensor\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate output\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=50,            # total length of the output\n",
    "        num_return_sequences=1,   # how many sequences you want\n",
    "        no_repeat_ngram_size=2,   # avoid repeating n-grams\n",
    "        do_sample=True,           # add randomness\n",
    "        top_k=50,                 # only consider top 50 tokens\n",
    "        top_p=0.95                # nucleus sampling (keep 95% prob. mass)\n",
    "    )\n",
    "\n",
    "# Decode and print the output\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "086b28c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21569,   318,   220]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"India is \", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c0487e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = model(input_ids, return_tensor=\"pt\")\n",
    "# len(temp.past_key_values), len(temp.past_key_values[0]), temp.past_key_values[0][0].shape\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e6a8f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight.shape == model.transformer.wte.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5e41ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.wpe.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.5.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.6.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.7.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.8.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.9.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.10.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.ln_1.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.ln_1.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.attn.c_attn.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.attn.c_attn.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.attn.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.ln_2.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.ln_2.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.mlp.c_fc.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.mlp.c_fc.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.mlp.c_proj.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.h.11.mlp.c_proj.bias\n",
      "torch.cuda.FloatTensor\n",
      "transformer.ln_f.weight\n",
      "torch.cuda.FloatTensor\n",
      "transformer.ln_f.bias\n",
      "torch.cuda.FloatTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, j in model.named_parameters():\n",
    "    print(i)\n",
    "    print(j.type())\n",
    "model.transformer.wte.weight.shape\n",
    "# attention dim = 64 -> 64 * 12 = 768\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ef5a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_emb = model.transformer.wte.weight.detach().cpu()\n",
    "SaveTensor(token_emb, \"emb.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4a2feaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc72ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict()\n",
    "# token_emb = model.transformer.wte.weight.detach().cpu().numpy()\n",
    "for i in range(50257):\n",
    "    vocab[tokenizer.decode([i])] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ce07c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"vocab.txt\", \"w\") as f:\n",
    "    json.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a466670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveModel(model): # save weights for model\n",
    "    filePath = r\"C:\\Users\\shiva\\Desktop\\IISC\\code\\NeuroCpp\\Projects\\The Dream\\weigths\"\n",
    "    os.mkdir(\"weigths\")\n",
    "    for name, weight in model.named_parameters():\n",
    "        SaveTensor(weight, os.path.join(filePath,name))\n",
    "        print(f\"{name} saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe11d797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight saved\n",
      "transformer.wpe.weight saved\n",
      "transformer.h.0.ln_1.weight saved\n",
      "transformer.h.0.ln_1.bias saved\n",
      "transformer.h.0.attn.c_attn.weight saved\n",
      "transformer.h.0.attn.c_attn.bias saved\n",
      "transformer.h.0.attn.c_proj.weight saved\n",
      "transformer.h.0.attn.c_proj.bias saved\n",
      "transformer.h.0.ln_2.weight saved\n",
      "transformer.h.0.ln_2.bias saved\n",
      "transformer.h.0.mlp.c_fc.weight saved\n",
      "transformer.h.0.mlp.c_fc.bias saved\n",
      "transformer.h.0.mlp.c_proj.weight saved\n",
      "transformer.h.0.mlp.c_proj.bias saved\n",
      "transformer.h.1.ln_1.weight saved\n",
      "transformer.h.1.ln_1.bias saved\n",
      "transformer.h.1.attn.c_attn.weight saved\n",
      "transformer.h.1.attn.c_attn.bias saved\n",
      "transformer.h.1.attn.c_proj.weight saved\n",
      "transformer.h.1.attn.c_proj.bias saved\n",
      "transformer.h.1.ln_2.weight saved\n",
      "transformer.h.1.ln_2.bias saved\n",
      "transformer.h.1.mlp.c_fc.weight saved\n",
      "transformer.h.1.mlp.c_fc.bias saved\n",
      "transformer.h.1.mlp.c_proj.weight saved\n",
      "transformer.h.1.mlp.c_proj.bias saved\n",
      "transformer.h.2.ln_1.weight saved\n",
      "transformer.h.2.ln_1.bias saved\n",
      "transformer.h.2.attn.c_attn.weight saved\n",
      "transformer.h.2.attn.c_attn.bias saved\n",
      "transformer.h.2.attn.c_proj.weight saved\n",
      "transformer.h.2.attn.c_proj.bias saved\n",
      "transformer.h.2.ln_2.weight saved\n",
      "transformer.h.2.ln_2.bias saved\n",
      "transformer.h.2.mlp.c_fc.weight saved\n",
      "transformer.h.2.mlp.c_fc.bias saved\n",
      "transformer.h.2.mlp.c_proj.weight saved\n",
      "transformer.h.2.mlp.c_proj.bias saved\n",
      "transformer.h.3.ln_1.weight saved\n",
      "transformer.h.3.ln_1.bias saved\n",
      "transformer.h.3.attn.c_attn.weight saved\n",
      "transformer.h.3.attn.c_attn.bias saved\n",
      "transformer.h.3.attn.c_proj.weight saved\n",
      "transformer.h.3.attn.c_proj.bias saved\n",
      "transformer.h.3.ln_2.weight saved\n",
      "transformer.h.3.ln_2.bias saved\n",
      "transformer.h.3.mlp.c_fc.weight saved\n",
      "transformer.h.3.mlp.c_fc.bias saved\n",
      "transformer.h.3.mlp.c_proj.weight saved\n",
      "transformer.h.3.mlp.c_proj.bias saved\n",
      "transformer.h.4.ln_1.weight saved\n",
      "transformer.h.4.ln_1.bias saved\n",
      "transformer.h.4.attn.c_attn.weight saved\n",
      "transformer.h.4.attn.c_attn.bias saved\n",
      "transformer.h.4.attn.c_proj.weight saved\n",
      "transformer.h.4.attn.c_proj.bias saved\n",
      "transformer.h.4.ln_2.weight saved\n",
      "transformer.h.4.ln_2.bias saved\n",
      "transformer.h.4.mlp.c_fc.weight saved\n",
      "transformer.h.4.mlp.c_fc.bias saved\n",
      "transformer.h.4.mlp.c_proj.weight saved\n",
      "transformer.h.4.mlp.c_proj.bias saved\n",
      "transformer.h.5.ln_1.weight saved\n",
      "transformer.h.5.ln_1.bias saved\n",
      "transformer.h.5.attn.c_attn.weight saved\n",
      "transformer.h.5.attn.c_attn.bias saved\n",
      "transformer.h.5.attn.c_proj.weight saved\n",
      "transformer.h.5.attn.c_proj.bias saved\n",
      "transformer.h.5.ln_2.weight saved\n",
      "transformer.h.5.ln_2.bias saved\n",
      "transformer.h.5.mlp.c_fc.weight saved\n",
      "transformer.h.5.mlp.c_fc.bias saved\n",
      "transformer.h.5.mlp.c_proj.weight saved\n",
      "transformer.h.5.mlp.c_proj.bias saved\n",
      "transformer.h.6.ln_1.weight saved\n",
      "transformer.h.6.ln_1.bias saved\n",
      "transformer.h.6.attn.c_attn.weight saved\n",
      "transformer.h.6.attn.c_attn.bias saved\n",
      "transformer.h.6.attn.c_proj.weight saved\n",
      "transformer.h.6.attn.c_proj.bias saved\n",
      "transformer.h.6.ln_2.weight saved\n",
      "transformer.h.6.ln_2.bias saved\n",
      "transformer.h.6.mlp.c_fc.weight saved\n",
      "transformer.h.6.mlp.c_fc.bias saved\n",
      "transformer.h.6.mlp.c_proj.weight saved\n",
      "transformer.h.6.mlp.c_proj.bias saved\n",
      "transformer.h.7.ln_1.weight saved\n",
      "transformer.h.7.ln_1.bias saved\n",
      "transformer.h.7.attn.c_attn.weight saved\n",
      "transformer.h.7.attn.c_attn.bias saved\n",
      "transformer.h.7.attn.c_proj.weight saved\n",
      "transformer.h.7.attn.c_proj.bias saved\n",
      "transformer.h.7.ln_2.weight saved\n",
      "transformer.h.7.ln_2.bias saved\n",
      "transformer.h.7.mlp.c_fc.weight saved\n",
      "transformer.h.7.mlp.c_fc.bias saved\n",
      "transformer.h.7.mlp.c_proj.weight saved\n",
      "transformer.h.7.mlp.c_proj.bias saved\n",
      "transformer.h.8.ln_1.weight saved\n",
      "transformer.h.8.ln_1.bias saved\n",
      "transformer.h.8.attn.c_attn.weight saved\n",
      "transformer.h.8.attn.c_attn.bias saved\n",
      "transformer.h.8.attn.c_proj.weight saved\n",
      "transformer.h.8.attn.c_proj.bias saved\n",
      "transformer.h.8.ln_2.weight saved\n",
      "transformer.h.8.ln_2.bias saved\n",
      "transformer.h.8.mlp.c_fc.weight saved\n",
      "transformer.h.8.mlp.c_fc.bias saved\n",
      "transformer.h.8.mlp.c_proj.weight saved\n",
      "transformer.h.8.mlp.c_proj.bias saved\n",
      "transformer.h.9.ln_1.weight saved\n",
      "transformer.h.9.ln_1.bias saved\n",
      "transformer.h.9.attn.c_attn.weight saved\n",
      "transformer.h.9.attn.c_attn.bias saved\n",
      "transformer.h.9.attn.c_proj.weight saved\n",
      "transformer.h.9.attn.c_proj.bias saved\n",
      "transformer.h.9.ln_2.weight saved\n",
      "transformer.h.9.ln_2.bias saved\n",
      "transformer.h.9.mlp.c_fc.weight saved\n",
      "transformer.h.9.mlp.c_fc.bias saved\n",
      "transformer.h.9.mlp.c_proj.weight saved\n",
      "transformer.h.9.mlp.c_proj.bias saved\n",
      "transformer.h.10.ln_1.weight saved\n",
      "transformer.h.10.ln_1.bias saved\n",
      "transformer.h.10.attn.c_attn.weight saved\n",
      "transformer.h.10.attn.c_attn.bias saved\n",
      "transformer.h.10.attn.c_proj.weight saved\n",
      "transformer.h.10.attn.c_proj.bias saved\n",
      "transformer.h.10.ln_2.weight saved\n",
      "transformer.h.10.ln_2.bias saved\n",
      "transformer.h.10.mlp.c_fc.weight saved\n",
      "transformer.h.10.mlp.c_fc.bias saved\n",
      "transformer.h.10.mlp.c_proj.weight saved\n",
      "transformer.h.10.mlp.c_proj.bias saved\n",
      "transformer.h.11.ln_1.weight saved\n",
      "transformer.h.11.ln_1.bias saved\n",
      "transformer.h.11.attn.c_attn.weight saved\n",
      "transformer.h.11.attn.c_attn.bias saved\n",
      "transformer.h.11.attn.c_proj.weight saved\n",
      "transformer.h.11.attn.c_proj.bias saved\n",
      "transformer.h.11.ln_2.weight saved\n",
      "transformer.h.11.ln_2.bias saved\n",
      "transformer.h.11.mlp.c_fc.weight saved\n",
      "transformer.h.11.mlp.c_fc.bias saved\n",
      "transformer.h.11.mlp.c_proj.weight saved\n",
      "transformer.h.11.mlp.c_proj.bias saved\n",
      "transformer.ln_f.weight saved\n",
      "transformer.ln_f.bias saved\n"
     ]
    }
   ],
   "source": [
    "SaveModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8696aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 3072])\n",
      "torch.Size([768, 3072])\n",
      "tensor(True, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "filePath = r\"C:\\Users\\shiva\\Desktop\\IISC\\code\\NeuroCpp\\Projects\\The Dream\\weigths\"\n",
    "mat = torch.from_numpy(np.load(os.path.join(filePath, \"transformer.h.0.mlp.c_fc.weight.npy\"))).to(\"cuda\")\n",
    "# mat == model.transformer.h[0].attn.c_attn.weight\n",
    "mat1 = model.transformer.h[0].mlp.c_fc.weight\n",
    "print(mat.shape)\n",
    "print(mat1.shape)\n",
    "print(torch.all(mat == mat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8dc415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
